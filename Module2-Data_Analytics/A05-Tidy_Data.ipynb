{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Tidy Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "This lesson meets the following learning objectives:\n",
    "- The ability to recognize and generate tidy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Read through all of the text in this page. This assignment provides step-by-step training divided into numbered sections. The sections often contain embeded exectable code for demonstration.  Section headers with icons have special meanings:  \n",
    "\n",
    "- <i class=\"fas fa-puzzle-piece\"></i> The puzzle icon indicates that the section provides a practice exercise that must be completed.  Follow the instructions for the exercise and do what it asks.  Exercises must be turned in for credit.\n",
    "- <i class=\"fa fa-cogs\"></i> The cogs icon indicates that the section provides a task to perform.  Follow the instructions to complete the task.  Tasks are not turned in for credit but must be completed to continue progress.\n",
    "\n",
    "Review the list of items in the **Expected Outcomes** section to check that you feel comfortable with the material you just learned. If you do not, then take some time to re-review that material again. If after re-review you are not comfortable, do not feel confident or do not understand the material, please ask questions on Slack to help.\n",
    "\n",
    "Follow the instructions in the **What to turn in** section to turn in the exercises of the assginment for course credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this assignment is to learn and practice with preparing tidy datasets.  Often data we are asked to analyze is provided to us in formats that are not easy to visualize or analyze.  Many visualization tools such as Seaborn or analytical tools such as supervised machine learning libraries expect data to be tidied.  It is important to know what \"tidy\" data is, how to reformat a data into a tidy format, and to organize our own scientific data to help ourselves and others analyze it.\n",
    "\n",
    "**What are \"tidy\" datasets?**\n",
    "\n",
    "> Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.\n",
    "\n",
    "\\- Wickham, Hadley. [Tidy Data](https://www.jstatsoft.org/article/view/v059i10). *Journal of Statistical Software*, 59.10 (2014): 1 - 23.\n",
    "\n",
    "Before proceeding, fully read the [Tidy Data paper](https://www.jstatsoft.org/article/view/v059i10) (quoted above) by Hadley Wickham. Once finished, return here to reinforce the techniques introduced by that paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i class=\"fa fa-cogs\"></i>  Notebook Setup\n",
    "As before, we import any needed packages at the top of our notebook. Let's import Numpy and Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Tidy Rules\n",
    "### 1.1 Recognizing data components\n",
    "To understand the rules for tidy data, we should define a few terms: 'variable', 'observation' and 'observational unit'.  \n",
    "\n",
    "+ **variable**:  \n",
    "  > A variable is a characteristic of a unit being observed... to which a numerical measure or a category... can be assigned (e.g. income, age, weight, etc., and “occupation”, “industry”, “disease”, etc.\n",
    "  \n",
    "  \\- [OECD Glossary of Statistical terms -- Variable](https://stats.oecd.org/glossary/detail.asp?ID=2857)\n",
    "+ **observation**:\n",
    "  > An observation is the value, at a particular period, of a particular variable\n",
    "  \n",
    "  \\- [OECD Glossary of Statistical terms -- Observation](https://stats.oecd.org/glossary/detail.asp?ID=6132)\n",
    "  \n",
    "+ **observational unit**:\n",
    "  > Observation units are those entities on which information is received and statistics are compiled.\n",
    "  \n",
    "  \\- [OECD Glossary of Statistical terms -- Observation Unit](https://stats.oecd.org/glossary/detail.asp?ID=1873)\n",
    "  \n",
    "With those definitions for reference, remember from the text that in order for a dataset to be considered \"tidy\" it must be organized into a table (i.e. Pandas DataFrame) and follow these rules:\n",
    "\n",
    "+ Each variable forms a unique column in the data frame.\n",
    "+ Each observation forms a row in the data frame.\n",
    "+ Each **type** of observational unit needs its own table.\n",
    "\n",
    "To demonstrate the meaning of these rules, let's first examine a dataset described in the Tidy Data paper. Execute the following lines of code that manually creates a Pandas data frame containing the example table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data rows and columns.\n",
    "data = [['John Smith', None, 2],\n",
    "        ['Jane Doe', 16, 11],\n",
    "        ['Mary Johnson', 3, 1]]\n",
    "# Create the list of labels for the data frame.\n",
    "headers = ['', 'Treatment_A', 'Treatment_B']\n",
    "# Create the data frame.\n",
    "pd.DataFrame(data, columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is not in tidy format.  Can you see why?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "Using the table above, answer the following:\n",
    "\n",
    "- What are the variables?\n",
    "- What are the observations?\n",
    "- What is the observable unit?\n",
    "- Are the variables columns?\n",
    "- Are the observations rows?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Spotting messy data\n",
    "The author provides a few useful indicators that help us spot untidied data:\n",
    "1. Column headers are values, not variable names.\n",
    "2. Multiple variables are stored in one column.\n",
    "3. Variables are stored in both rows and columns.\n",
    "4. Multiple types of observational units are stored in the same table.\n",
    "5. A single observational unit is stored in multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's look at a data set that the author borrowed from the Pew Reserach Center that provides religious affiliation and yearly income ranges for individuals surveyed. Execute the following code which manually puts that data into a Pandas data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['Agnostic',27,34,60,81,76,137],\n",
    "        ['Atheist',12,27,37,52,35,70],\n",
    "        ['Buddhist',27,21,30,34,33,58],\n",
    "        ['Catholic',418,617,732,670,638,1116],\n",
    "        ['Don\\'t know/refused',15,14,15,11,10,35],\n",
    "        ['Evangelical Prot',575,869,1064,982,881,1486],\n",
    "        ['Hindu',1,9,7,9,11,34],\n",
    "        ['Historically Black Prot',228,244,236,238,197,223],\n",
    "        ['Jehovah\\'s Witness',20,27,24,24,21,30],\n",
    "        ['Jewish',19,19,25,25,30,95]]\n",
    "headers = ['religion','<$10k','$10-20k','$20-30k','$30-40k','$40-50k','$50-75k']\n",
    "religion = pd.DataFrame(data, columns=headers)\n",
    "religion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, consider the data frame also provided by the author. For this data,  the demographic groups are broken down by sex (m, f) and age (0–14, 15–25, 25–34, 35–44, 45–54, 55–64, 65+, or unknown). Execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['AD', 2000, 0, 0, 1, 0, 0, 0, 0, None, None],\n",
    "        ['AE', 2000, 2, 4, 4, 6, 5, 12, 10, None, 3],\n",
    "        ['AF', 2000, 52, 228, 183, 149, 129, 94, 80, None, 93],\n",
    "        ['AG', 2000, 0, 0, 0, 0, 0, 0, 1, None, 1],\n",
    "        ['AL', 2000, 2, 19, 21, 14, 24, 19, 16, None, 3],\n",
    "        ['AM', 2000, 2, 152, 130, 131, 63, 26, 21, None, 1],\n",
    "        ['AN', 2000, 0, 0, 1, 2, 0, 0, 0, None, 0],\n",
    "        ['AO', 2000, 186, 999, 1003, 912, 482, 312, 194, None, 247],\n",
    "        ['AR', 2000, 97, 278, 594, 402, 419, 368, 330, None, 121],\n",
    "        ['AS', 2000, None, None, None, None, 1, 1, None, None, None]]\n",
    "headers = ['country', 'year', 'm014', 'm1524', 'm2534', 'm3544', 'm4554', 'm5564', \n",
    "           'm65', 'mu', 'f014']\n",
    "demographics = pd.DataFrame(data, columns=headers)\n",
    "demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "\n",
    "Using the data set above:\n",
    "\n",
    "- Explain why the data above is untidy?\n",
    "- What are the variables?  \n",
    "- What are the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "\n",
    "Using the data set above:\n",
    "\n",
    "- Explain why the data above is untidy?\n",
    "- What are the variables?  \n",
    "- What are the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Melting and Pivoting Data\n",
    "In the Tidy paper, the author indicated that many times a data set can be corrected, or tidied, by first \"melting\" the data. Fortunately, Pandas provides the `pd.melt` function! See the [online documenation for pd.melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) for full usage instructions.  The author provides five different use cases where melting (and other transformations) can be performed:\n",
    "\n",
    "1. Column headers are values, not variable names.\n",
    "2. Multiple variables are stored in one column.\n",
    "3. Variables are stored in both rows and columns.\n",
    "4. Multiple types of observational units are stored in the same table.\n",
    "5. A single observational unit is stored in multiple tables.\n",
    "\n",
    "We will explore only a few of these use cases.  However, the techniques provided by these examples will help with melting for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Use Case #1: column headers are values\n",
    "To demonsrate melting let's create a sample dataframe that provides the progress level of different groups of individuals in a process that has two stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Group': {0: 'A', 1: 'B', 2: 'C'},\n",
    "                   'Stage1': {0: 1, 1: 3, 2: 5},\n",
    "                   'Stage2': {0: 2, 1: 4, 2: 6}})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that this dataset does not follow tidy rules.  This is because information about the stage is housed in the header (i.e. two different stages: stage1 and stage2). To tidy this up, we should have a separate column that indicates the stage and a corresponding column that indicates the observation for each stage.\n",
    "\n",
    "The first step to correct this is to melt the data. To melt a dataset using Pandas, you must indicate which columns in the current data frame should be kept as columns and which columns should be melted (also called **unpivoted**) to rows.  This is indicated using two arguments provided to `pd.melt`:\n",
    "\n",
    "- `id_vars`: indicates the columns to use as identifier variables.  These columns remain as columns in the dataframe after melting.\n",
    "- `value_vars`: indicates the columns to melt (unpivot). If not specified, then all columns that are not set as `id_vars` are used.  \n",
    "  - The column header becomes a value in a new column\n",
    "  - The value within the original column is matched with the header value in an adjacent column.\n",
    "\n",
    "As an example, let's melt the example dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.melt(df, id_vars=['Group'], value_vars=['Stage1', 'Stage2'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the new column labels named 'variable' and 'value' do not indicate what the data the colomn contains.  We can either set these manually using:\n",
    "\n",
    "```python\n",
    "df2.columns = ['Group', 'Stage', 'Level']\n",
    "```\n",
    "\n",
    "Or, we can provide the new labels when we melt the data using the `var_name` and `value_name` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.melt(df, id_vars=['Group'], value_vars=['Stage1', 'Stage2'],\n",
    "             var_name='Stage', value_name='Level')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "Using the `pd.melt` function, melt the demographics data introduced in section 2. Be sure to:\n",
    "- Set the column headers correctly. \n",
    "- Order by country \n",
    "- Print the first 10 lines of the resulting melted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Use Case #2: multiple variables stored in one column\n",
    "Sometimes, melting the data is not enough.  Consider the demographics example where the sex and the age range are combined into a single column label.  In Task 3a we melted that dataset:\n",
    "\n",
    "<table>\n",
    "    <tr><th>country</th><th>year</th><th>age</th><th>freq</th></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m014</td><td>0</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m5564</td><td>0</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m3544</td><td>0</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m65</td><td>0</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m2534</td><td>1</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>mu</td><td>None</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m1524</td><td>0</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>f014</td><td>NaN</td></tr>\n",
    "    <tr><td>AD</td><td>2000</td><td>m4554</td><td>0</td></tr>\n",
    "    <tr><td>AE</td><td>2000</td><td>m5564</td><td>12</td></tr>\n",
    "</table>\n",
    "\n",
    "We need to split that `age` column into three different columns corresponding to the sex, minimum age and maximum age.  To do this, we can use the following line of code:\n",
    "\n",
    "```Python\n",
    "temp_df = melted_df[\"age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\")    \n",
    "\n",
    "```\n",
    "Remember, that Pandas provides a [pandas.Series.str.extract](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html) function for manipulating the string values of a Series, and each column in a Pandas dataframe is a series. We can use this function to break apart the value into three separate columns.\n",
    "\n",
    "Observe the argument provided to the `.str.extract` function: `(\\D)(\\d+)(\\d{2})`. This type of string is called a regular expression (RE).  We will not cover regular expressions in detail, but they are a powerful method for parsing strings to either match elements of the string or to split them.  An [introduction to REs](https://docs.python.org/3.4/howto/regex.html#regex-howto) for Python and [a full syntax description](https://docs.python.org/3.4/library/re.html#regular-expression-syntax) is available online.  But here is a short explanation for the elements of the RE above:\n",
    "\n",
    "+ `(\\D)`: Matches any single character which is not a digit.  This correspondes to the sex: 'f' or 'm'.\n",
    "+ `(\\d+)`: Matches one or more digits.  This correspondes to the minimum age which may be one or more digits.\n",
    "+ `(\\d{2})`: Matches exactly two digits.  This requires that the last two digits are the max age.\n",
    "\n",
    "Let's try it and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the demographics dataset and sort by country:\n",
    "melted_df = pd.melt(demographics, id_vars=[\"country\", \"year\"],\n",
    "                    var_name=\"age\", value_name=\"freq\")\n",
    "melted_df = melted_df.sort_values(by=[\"country\"])\n",
    "\n",
    "# Split 'age' column into a new dataframe containing the three components: sex, \n",
    "# minimum age and maximum age.\n",
    "temp_df = melted_df[\"age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\")\n",
    "temp_df.columns = ['sex', 'min_age', 'max_age']\n",
    "temp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Use Case #3: variables are in both rows and columns\n",
    "\n",
    "Consider the following dataset which contains the daily weather records for five months in 2010 for the MX17004 weather station in Mexico. Each day of the month has it's own column (e.g. d1, d2, d3, etc.).  The example data only provides the first 8 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['MX17004',2010,1,'tmax',None,None,None,None,None,None,None,None],\n",
    "        ['MX17004',2010,1,'tmin',None,None,None,None,None,None,None,None],\n",
    "        ['MX17004',2010,2,'tmax',None,27.3,24.1,None,None,None,None,None],\n",
    "        ['MX17004',2010,2,'tmin',None,14.4,14.4,None,None,None,None,None],\n",
    "        ['MX17004',2010,3,'tmax',None,None,None,None,32.1,None,None,None],\n",
    "        ['MX17004',2010,3,'tmin',None,None,None,None,14.2,None,None,None],\n",
    "        ['MX17004',2010,4,'tmax',None,None,None,None,None,None,None,None],\n",
    "        ['MX17004',2010,4,'tmin',None,None,None,None,None,None,None,None],\n",
    "        ['MX17004',2010,5,'tmax',None,None,None,None,None,None,None,None],\n",
    "        ['MX17004',2010,5,'tmin',None,None,None,None,None,None,None,None]]\n",
    "headers = ['id','year','month','element','d1','d2','d3','d4','d5','d6','d7','d8']\n",
    "weather = pd.DataFrame(data, columns=headers)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset there are two problems.  First, we have a violation of use case #1 where observations are stored in the column labels for the days (e.g. d1, d2, d3, etc.). Second, we have a violation of use case #3. Observe that the 'element' column contains values that should be variables.  We want the min and max temperatures for each day as columns.  \n",
    "\n",
    "First, let's deal with the first problem by including `id`, `year`, `month` and `element` as `id_vars`.  Observe that we will currently not try to tidy the `element` column. We want to remove the 'd' from the day so let's name the column `temp_day`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_weather = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'],\n",
    "        var_name='temp_day', value_name='temperature')\n",
    "melted_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create an actual date for the measurement rather than storing year, month and day separately.  Let's add a new column to the dataframe named 'day' that uses a regular expression to remove the letter 'd' from the beginning of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_weather[\"day\"] = melted_weather[\"temp_day\"].str.extract(\"d(\\d+)\", expand=False)  \n",
    "melted_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the year, month and day to form a proper date using the Pandas `apply` function. Execute the code below and observe the in-line comments for the meaning of each line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datetime library.\n",
    "import datetime\n",
    "\n",
    "# Our year, month, and day columns must be numeric. Currently they are \n",
    "# strings. We can use the Pandas \"apply\" function to convert these columns.\n",
    "melted_weather[[\"year\", \"month\", \"day\"]] = melted_weather[[\"year\", \"month\", \"day\"]].apply(pd.to_numeric)\n",
    "\n",
    "# Convert temperature to numeric as well\n",
    "melted_weather[[\"temperature\"]] = melted_weather[[\"temperature\"]].apply(pd.to_numeric)\n",
    "\n",
    "# We want to use the Python datetime function to cobmine the year, month and day\n",
    "# into a proper date. In Python this is a datetime object, not a string. So, we \n",
    "# need to use the apply function, just like above, to convert the dates. We'll\n",
    "# create a simple little function that we'll use to apply the datetime change.\n",
    "def create_date(row):\n",
    "    return datetime.datetime(year=row[\"year\"], month=int(row[\"month\"]), day=row[\"day\"])\n",
    "\n",
    "# Apply the create_date function to each row of our data frame for the \"date\" column.\n",
    "melted_weather[\"date\"] = melted_weather.apply(lambda row: create_date(row), axis=1)\n",
    "\n",
    "# Now take a look!\n",
    "melted_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our date corrected, and properly melted, we can address the second problem: the `element` column containing variable names.  To fix this we need to do the opposite of melting and we need to **pivot**.  To do this we can use the [pd.pivot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html) function.  This function takes the following arguments:\n",
    "\n",
    "- `index`: indicates the columns to use to make the new frame’s index. If None, uses existing index\n",
    "- `columns`: indicates the column to use whose values will become the new frame’s columns.\n",
    "- `values`: indicates the columns to use for populating new frame’s values.\n",
    "\n",
    "Let's use the `pivot_table` function, which is a generalization of the `pivot` function that handles duplicate values or one index/column pair. This will move the `element` column values to be new columns in our data frame.  But first, we will also want to drop unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "weather_min = melted_weather.drop(['year', 'month', 'day', 'temp_day'], axis=1)\n",
    "weather_min.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot and reset indexes. The pivot_table function automatically removes rows with null values.\n",
    "weather_tidy = weather_min.pivot_table(index=[\"id\",\"date\"], columns=\"element\", values=\"temperature\")\n",
    "weather_tidy.reset_index(drop=False, inplace=True)\n",
    "weather_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather data is now tidy (although rather small).  \n",
    "\n",
    "Observe, that in the code above, we called the function `reset_index` on the Tidy'ed weather data.  If we do not do this, then the row indexes are not incremental within the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "Download the [PI_DataSet.txt](https://hivdb.stanford.edu/download/GenoPhenoDatasets/PI_DataSet.txt) file from [HIV Drug Resistance Database](https://hivdb.stanford.edu/pages/genopheno.dataset.html). Store the file in the same directory as the practice notebook for this assignment.\n",
    "\n",
    "Here is the meaning of data columns:\n",
    "- SeqID:  a numeric identifier for a unique HIV isolate protease sequence.  Note: disruption of the protease inhibits HIV’s ability to reproduce.\n",
    "- The Next 8 columns are identifiers for unique protease inhibitor class drugs.  \n",
    "  - The values in these columns are the fold resistance over wild type (the HIV strain susceptible to all drugs).\n",
    "  - Fold change is the ratio of the drug concentration needed to inhibit the isolate.\n",
    "- The latter columns, with P as a prefix, are the positions of the amino acids in the protease. \n",
    "  - '-' indicates consensus.\n",
    "  - '.' indicates no sequence.\n",
    "  - '#' indicates an insertion. \n",
    "  - '~' indicates a deletion;.\n",
    "  - '*' indicates a stop codon\n",
    "  - a letter indicates one letter Amino Acid substitution. \n",
    "  - two and more amino acid codes indicates a mixture. \n",
    "\n",
    "Import this dataset into your notebook, view the top few rows of the data and respond to these questions:\n",
    "\n",
    "- What are the variables?  \n",
    "- What are the observations?   \n",
    "- What are the values?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. <i class=\"fas fa-puzzle-piece\"></i> Practice\n",
    "\n",
    "In the cell below notebook, perform the following.\n",
    "\n",
    "Use the data retreived from task 3b, generate a data frame containing a Tidy’ed set of values for drug concentration fold change. Be sure to:\n",
    "\n",
    "- Remove the all columns but the SeqID and the protease inhibitors.\n",
    "- Set the column names as ‘SeqID’, ‘Drug’ and ‘Fold_change’.\n",
    "- Order the data frame first by sequence ID and then by Drug name\n",
    "- Reset the row indexes\n",
    "- Display the first 10 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outcomes\n",
    "At this point, you should feel comfortable with the following:\n",
    "- Know the Tidy rules.\n",
    "- Spotting untidy data.\n",
    "- Melting and pivoting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to Turn in?\n",
    "Be sure to **commit** and **push** your changes to this notebook.  All practice exercises should be completed.  Once completed, send a **Slack message** to the instructor indicating you have completed this assignment. The instructor will verify all work is completed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
